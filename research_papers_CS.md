# Research Articles

## Decision Fatigue in Machine Learning

### Article 1 (14 Citation)

**DOI:** [Reducing user fatigue within an interactive evolutionary design system using clustering and case-based reasoning](https://doi.org/10.1080/03052150903081556)

**Summary:** User fatigue is a limiting factor in interactive evolutionary design and optimization systems. This work illustrates how user fatigue arising from repetitive evaluations can be reduced by incorporating a case-based machine learning system and by clustering the population. An interactive evolutionary design system for urban furniture design is introduced and used as a test-bed for the implementation. The role of clustering within the system is described and initial results are presented. Results obtained from previous work supporting the choice of a case-based approach to machine learning are then presented and, finally, the results from a multi-user study of the performance of the case-based learning system when applied to the design of urban furniture are included.

---

### Article 2 (196 Citations)

**DOI:** [A Review of User Interface Design for Interactive Machine Learning](https://doi.org/10.1145/3185517)

**Abstract:** Interactive Machine Learning (IML) seeks to complement human perception and intelligence by tightly integrating these strengths with the computational power and speed of computers. The interactive process is designed to involve input from the user but does not require the background knowledge or experience that might be necessary to work with more traditional machine learning techniques. Under the IML process, non-experts can apply their domain knowledge and insight over otherwise unwieldy datasets to find patterns of interest or develop complex data-driven applications. This process is co-adaptive in nature and relies on careful management of the interaction between human and machine. User interface design is fundamental to the success of this approach, yet there is a lack of consolidated principles on how such an interface should be implemented. This article presents a detailed review and characterisation of Interactive Machine Learning from an interactive systems perspective. We propose and describe a structural and behavioural model of a generalised IML system and identify solution principles for building effective interfaces for IML. Where possible, these emergent solution principles are contextualised by reference to the broader human-computer interaction literature. Finally, we identify strands of user interface research key to unlocking more efficient and productive non-expert interactive machine learning applications.


---

## Article 3 (654 Citations)


**DOI:** [Power to the People: The Role of Humans in Interactive Machine Learning](https://doi.org/10.1609/AIMAG.V35I4.2513)

**Summary:** Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.


## Article 4 (1 Citation)

**DOI:** [The Effects of Reluctant and Fallible Users in Interactive Online Machine Learning](https://ceur-ws.org/Vol-2660/ialatecml_paper4.pdf)

**Abstract:** In interactive machine learning it is important to select the
most informative data instances to label in order to minimize the effort of the human user. There are basically two categories of interactive
machine learning. In the first category, active learning, it is the computational learner that selects which data to be labelled by the human user,
whereas in the second one, machine teaching, the selection is done by
the human teacher. It is often assumed that the human user is a perfect
oracle, i.e., a label will always be provided in accordance with the interactive learning strategy and that this label will always be correct. In
real-world scenarios however, these assumptions typically do not hold.
In this work, we investigate how the reliability of the user providing
labels affects the performance of online machine learning. Specifically,
we study reluctance, i.e., to what extent the user does not provide labels in accordance with the strategy, and fallibility, i.e., to what extent
the provided labels are incorrect. We show results of experiments on a
benchmark dataset as well as a synthetically created dataset. By varying
the degree of reluctance and fallibility of the user, the robustness of the
different interactive learning strategies and machine learning algorithms
is explored. The experiments show that there is a varying robustness of
the strategies and algorithms. Moreover, certain machine learning algorithms are more robust towards reluctance compared to fallibility, while
the opposite is true for others.

<!-- Add more articles in the same format -->